# 南峰黑私房手作系统
# 目录--设计接口+知识点
## 用户管理
实现用户的注册、登录功能，集成JWT进行身份认证与权限控制，确保系统安全访问。

**核心逻辑**
1. 用户注册  

首先用户传入registerDTO[用户名，密码，手机号]，   
然后UserService进行注册，并给用户分配ID,创建用户对象（加密密码）。  
若库中无重名数据则注册成功，返回data[用户ID:name]到前端；
2. 用户登录  

用户传入UserLoginDTO[name,password]进login  

login:1.查找username；2.验证password 3.生成token并返回  
jwtUtil.generateToken(userDO.getUsername()):  
1.创建当前时间和过期时间（当前时间+配置的过期秒数）   
2.使用JJWT库构建JWT token：设置主题(subject)为传入的用户标识+设置签发时间+设置过期时间+使用HS512算法和密钥签名  
3.JWT身份认证  

3. 在JWT中，Token由三部分组成，用点(.)分隔：

Header（头部）：由JJWT库自动创建,包含算法信息：{"alg": "HS512", "typ": "JWT"}   
Payload（载荷）：sub (subject)：用户名+iat (issued at)：签发时间+exp (expiration)  
Signature（签名）：   
由JJWT库使用HS512算法生成   
通过对Header和Payload的Base64编码字符串，加上密钥(jwtConfig.getSecret())进行签名
4. JWT配置管理 

JWT配置类的作用：   
读取配置属性：

从application.yml或application.properties文件中读取JWT相关配置  
使用@ConfigurationProperties(prefix = "jwt")注解绑定配置

存储配置参数：

secret：JWT签名密钥，用于token的签名和验证   
expiration：token过期时间（秒），控制token的有效期   
提供getter/setter方法：允许其他类获取和设置JWT配置参数
## 商品管理
支持商品的上架、下架、分类管理及库存控制，满足商品信息维护和展示需求。

**核心代码：**  

1.**创建工作簿和工作表**：

    Workbook workbook = new XSSFWorkbook();  
    Sheet sheet = workbook.createSheet("商品数据");
   
首先创建了一个新的Excel工作簿（`Workbook`），然后在其中创建了一个名为“商品数据”的工作表（`Sheet`）。  
`XSSFWorkbook`是Apache POI库中用于处理.xlsx格式文件的类。

2.**设置列标题行**：

    Row headerRow = sheet.createRow(0);   
    headerRow.createCell(0).setCellValue("商品ID");   
    headerRow.createCell(1).setCellValue("商品名称");   
    
在工作表的第一行（即索引为0的行）创建了一个标题行（`Row headerRow`），并在该行的各个单元格（`Cell`）中分别设置了列标题  

3.**创建日期格式化对象**：   

    SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");   

如果移除日期格式化的功能，那么在Excel表格中显示的创建时间将会是原始的Date对象toString()的结果，通常是类似"Mon Nov 03 15:30:45 CST 2025"，而不是"2025-11-03 15:30:45"。   

4.**填充商品数据**：

    int rowNum = 1;
    for (ProductDO product : productList) {
        Row row = sheet.createRow(rowNum++);
        row.createCell(0).setCellValue(product.getId());
        row.createCell(1).setCellValue(product.getName());
        if (product.getCreateTime() != null) {
            row.createCell(7).setCellValue(sdf.format(product.getCreateTime()));
        }
    }
   对于每个商品，代码会在工作表中创建一个新的行（`Row`），并从该行的索引1开始为每一列填充数据。  

5.**设置HTTP响应头**：
1. `response.setContentType("application/vnd.openxmlformats-officedocument.spreadsheetml.sheet");`  
设置响应的内容类型为Excel文件格式（xlsx）。浏览器会根据这个MIME类型识别这是一个Excel文件。

2. `ContentDisposition contentDisposition = ContentDisposition.attachment()
        .filename("商品数据.xlsx", StandardCharsets.UTF_8)
        .build();`  
使用Spring框架的ContentDisposition工具类创建了一个附件类型的Content-Disposition头部信息，并指定了文件名为"商品数据.xlsx"，同时使用UTF-8字符集编码以支持中文文件名。

3. `response.setHeader("Content-Disposition", contentDisposition.toString());`  
将上面构建好的Content-Disposition对象转换成字符串并设置到HTTP响应头中。这告诉浏览器应该将响应内容作为附件下载，并提示默认文件名。

4. `workbook.write(response.getOutputStream());`  
将Apache POI创建的Excel工作簿直接写入HTTP响应的输出流中，这样客户端就可以接收到完整的Excel文件内容。

整个过程就是：
- 告诉浏览器返回的是一个Excel文件
- 告诉浏览器应该如何处理这个文件（作为附件下载）
- 把实际的Excel文件内容发送给浏览器

6.**关闭工作簿**：
    workbook.close();

知识点总结：
1. Apache POI库   

Q1：读取 Excel 的典型步骤？
-  通过 WorkbookFactory.create(inputStream) 创建 Workbook
-  遍历 Sheet → Row → Cell
-  使用 DataFormatter 格式化单元格值（避免类型错误）  

Q2：常见异常处理
-  EncryptedDocumentException：文件加密时抛出，需解密后读取
-  InvalidFormatException：文件格式不匹配（如用 XSSF 读取 .xls 文件）  

Q3: 性能优化技巧   
- 避免频繁创建对象：复用 CellStyle 和 Font   
- 批量写入数据：使用 sheet.flushRows() 控制内存   
- 关闭资源：确保 workbook.close() 和 inputStream.close()   
- 使用事件模型：对于只读场景，采用 SAX 解析（如 XSSF and SAX (Event API)）

2. 各种判空方式的总结对比表：

| 方法 | 用途 | 是否检查null | 是否检查空字符串 | 是否检查空白字符 | 需要先决条件 |
|------|------|------|-----------|----------|--------|
| `== null` | 检查对象是否为null | ✅  | ❌  | ❌ |  |
| `!= null` | 检查对象是否存在 | ✅  | ❌  | ❌ |  |
| `isEmpty()` | 检查字符串长度是否为0 | ❌  | ✅  | ❌ | 对象不能为null |
| `trim().isEmpty()` | 检查去除空白后是否为空 | ❌  | ✅  | ✅ (间接) | 对象不能为null |
| `isBlank()` (Apache Commons) | 检查是否为空或仅含空白字符 | ✅  | ✅  | ✅  |  |
| `Objects.isNull()` | 检查对象是否为null(JDK 8+) | ✅  | ❌  | ❌  |  |
| `Objects.nonNull()` | 检查对象是否存在(JDK 8+) | ✅  | ❌  | ❌  |  |

注意事项：
- `isEmpty()`和`trim()`都需要对象不为null，否则会抛出`NullPointerException`
- Apache Commons Lang的`isBlank()`是最全面的方法，但需要额外依赖
- 在实际开发中，通常组合使用`== null || isEmpty()`来保证安全  

3. MyBatis Plus高级特性知识点总结

1.实现MetaObjectHandler自动填充创建时间和更新时间等字段

MetaObjectHandler是MyBatis Plus提供的元数据对象处理器，用于自动处理字段的填充操作，无需在业务代码中手动设置创建时间、更新时间等公共字段。

```    
public void insertFill(MetaObject metaObject) {
        //从要插入的对象中获取名为"createTime"的字段值
        Object createTime = getFieldValByName("createTime", metaObject);
        if (createTime == null) {
            //参数分别是：要操作的对象，要填充的字段名，字段的数据类型，具体的值
            this.strictInsertFill(metaObject, "createTime", Date.class, new Date());
        }
```
**实现要点**：
- 创建自定义MetaObjectHandler实现类，实现insertFill和updateFill方法
- 在实体类字段上使用@TableField(fill = FieldFill.INSERT/UPDATE/INSERT_UPDATE)注解标记需要自动填充的字段
- INSERT表示插入时填充，UPDATE表示更新时填充，INSERT_UPDATE表示插入和更新都填充

**面试重点**  
Q1：为什么要使用自动填充？   
A：避免在每个业务方法中重复设置公共字段（如创建时间、更新时间、操作人等），减少样板代码，统一管理公共字段的赋值逻辑，降低维护成本。

Q2：自动填充是如何实现的？  
A：通过MetaObjectHandler接口，在MyBatis执行SQL前拦截，通过反射机制获取并设置指定字段的值。分为insertFill（插入填充）和updateFill（更新填充）两个时机。

2.添加乐观锁机制防止并发更新冲突

乐观锁是一种并发控制机制，假设数据一般不会发生冲突，只在提交更新时检查是否违反了并发控制规则。  
MyBatis Plus通过version字段实现乐观锁机制。

**实现要点**
- 在实体类中添加@Version注解的version字段
- 配置OptimisticLockerInnerInterceptor插件
- 更新数据时会自动在SQL中添加version条件，确保只有version匹配时才能更新成功；如果更新影响行数为0，则说明版本已变化，抛出异常。

**面试重点**  
Q1：乐观锁的优缺点？  
A：  
性能好，不会阻塞其他线程；  
缺点是在高并发写场景下可能导致更新失败率较高，需要业务方处理重试逻辑。

Q2：乐观锁适用场景？  
A：读多写少的场景，如电商商品信息、用户资料等更新频率较低但并发可能较高的场景。

3.实现逻辑删除而非物理删除  
**实现要点**
- 在实体类中添加@TableLogic注解的deleted字段
- 在application.yml中配置全局逻辑删除规则
- 查询、更新操作会自动添加未删除条件，删除操作会转为更新操作

**面试重点**  
Q1：逻辑删除的优缺点？   
A：优点是可以恢复误删数据，便于审计追踪，保持数据完整性；缺点是增加存储开销，查询需要额外过滤条件，可能影响性能。

Q2：什么场景适合使用逻辑删除？   
A：对数据安全性要求高的场景，如订单记录、财务数据、用户信息等重要业务数据，以及需要数据恢复和审计功能的系统。

## 订单管理
处理用户通过微信下单的操作，支持自取和快递两种配送方式的选择，并记录完整订单流程。

### 1. totalAmount：

Q1：为什么在计算订单总金额时使用AtomicReference？
```java
AtomicReference<BigDecimal> totalAmount = new AtomicReference<>(BigDecimal.ZERO);
```
A：使用AtomicReference主要有以下原因：

1. 线程安全性：AtomicReference提供了线程安全的操作，在多线程环境下可以安全地更新totalAmount值
2. Lambda表达式限制：在Java中，lambda表达式内部只能访问final或等效final的变量，而AtomicReference允许我们在lambda内部修改其包装的值
3. 避免重复创建对象：通过set/get方法可以不断更新同一个引用中的值，而不需要创建新的BigDecimal对象

Q2：为什么使用BigDecimal而不是double或float来计算金额？   
A：  
精度问题：  
- float/double是二进制浮点数，无法精确表示某些十进制小数（如0.1）
- BigDecimal提供任意精度的定点数，可以精确表示任何有理数
   ```java
   // 错误示例 - 使用double会有精度问题
   double result = 0.1 + 0.2; // 结果是0.30000000000000004
   
   // 正确示例 - 使用BigDecimal保证精度
   BigDecimal result = BigDecimal.valueOf(0.1).add(BigDecimal.valueOf(0.2)); // 结果是0.3
   ```

Q3：为什么在循环中计算总金额而不是数据库聚合查询？  
A： 
1. 数据一致性：循环计算可以确保使用的是当前最新的商品价格和库存信息
2. 业务逻辑集中：在订单创建的核心业务逻辑中完成计算，便于维护和理解
3. 性能考虑：订单商品数量通常较少（一般几到几十个），循环计算性能影响很小
4. 错误处理：可以及时发现商品下架或库存不足等问题

Q4：如何优化订单金额计算的性能？   
A： 可以考虑以下优化方案：
1. 批量查询商品信息：一次性查询所有商品而不是逐个查询
2. 缓存热点商品：对经常购买的商品信息进行缓存
3. 并行计算：对多个商品的小计计算可以并行处理
4. 预计算优化：在下单前的商品详情页面就显示预估总价

Q5：如果订单商品数量巨大，如何优化计算？  
A： 针对大量商品的订单可以采用：
- 分批处理：将大量商品分批处理，避免内存溢出 
- 流式计算：使用Java 8 Stream API进行流式处理
- 数据库聚合：对于纯金额统计，可以考虑使用数据库聚合函数
- 异步计算：将金额计算放到异步任务中处理  

### 2. 事务传播行为和隔离级别  
传播行为常见场景：
- REQUIRED：如果当前存在事务就加入，否则新建（最常用）【要么凑桌，要么单开一桌】 ：绝大多数业务  
- REQUIRES_NEW：新建事务，如果当前有事务则挂起【后到的vip只能单开一桌吃饭】 ：独立的辅助业务（如日志、审计）  
- SUPPORTS：支持当前事务，没有则以非事务方式执行【只凑桌，否则自己吃】：大部分只读或不重要的操作   

隔离级别应用场景：
- READ_COMMITTED：避免脏读，适用于大多数业务场景   
- REPEATABLE_READ：避免不可重复读，适用于需要多次读取相同数据的场景   
- SERIALIZABLE：最高隔离级别，完全避免并发问题但性能最差
  
**事务并发问题**  
关于三个并发问题我的理解：   
事务A所做的事：读写[commit]读   
1.脏读：B在A写完commit前读数据   
2.不可重复读：B在A写前读一次，在A写完commit后又读一次，两次结果不同   
3.幻读：B在A写前查一次，在A删完commit后又查一次，两次结果不同

（酒店预订系统）比喻：   
假设你是一个前台（事务B），正在处理一个长订单。  
**脏读**  
另一个前台（事务A）正在为客人办理入住，他在电脑上把101房间的状态从“空”改成了“住”，但还没有点击“确认完成”（即未提交）。
这时你（事务B）去查101房的状态，系统显示为“住”。于是你告诉新客人101房没了。  
但是，之前那个前台（事务A）发现客人证件有问题，取消了操作（回滚了事务），101房的状态又变回了“空”。  
后果：你得到了一条错误信息，可能因此流失了客人。

**不可重复读**  
你（事务B）接到一个客人电话，他问：“101房是海景房吗？” 你查了一下系统，显示“是”。（第一次读）   
在你回答他之前，另一个前台（事务A）接到101房客人投诉，将101房类型从“海景房”更新为“园景房”并提交了。   
这时客人又问：“你确定是海景房吗？” 你再次查询（第二次读），发现系统显示变成了“园景房”。  
后果：在同一个通话（事务）中，你对同一个问题给出了前后不一致的答案，显得非常不专业。

**幻读**   
你（事务B）想统计一下今天还有多少间空房。你执行查询 WHERE status=‘空’，系统返回有10间。（第一次读）   
此时，另一个前台（事务A）成功为一位网络预订的客人办理了入住，插入了一条新的入住记录到数据库（房间号是102），并提交了。   
你准备打印空房列表，于是再次执行相同的查询 WHERE status=‘空’。（第二次读）   
后果：这次系统只返回了9间房。你感到非常困惑，刚才明明有10间，怎么凭空少了一间？就像出现了“幻觉”一样。这条新出现的102房记录，就是“幻影行”。

幻读是因为在同一个事务同时存在快照读和当前读，数据又被修改了，读到的数据一个是之前版本的快照，一个是当前数据库的数据
1. 核心概念  
* **快照读**：
    *   普通的 `SELECT` 语句（非加锁查询）。
    *   在 **可重复读** 隔离级别下，它读取的是事务开始时的**一致性视图**。这个视图是该事务启动时数据库的一个“快照”，无论其他事务如何修改并提交数据，这个快照在整个事务期间都保持不变。
    *   **目的**：实现**非阻塞读**，保证可重复读。
* **当前读**：
    *   加锁的读操作，如 `SELECT ... FOR UPDATE`, `SELECT ... LOCK IN SHARE MODE`，以及 `UPDATE`, `DELETE`, `INSERT` 操作本身。
    *   它读取的是数据库的**最新提交版本**的数据，并且会对其读取的数据加上锁，以防止其他事务并发修改。
    *   **目的**：保证在修改数据时，基于的是最新的、准确的数据状态。

2. 幻读产生的典型场景（结合你的理解）   
假设在 **可重复读** 隔离级别下，事务B执行以下操作：  
1.**事务B开始**。   
2.**快照读**：`SELECT * FROM users WHERE age > 20;` // 返回了10条记录。这次读取基于事务开始时的快照。   
3.**此时，事务A插入了一条 `age=25` 的新记录并提交**。这条记录对于事务B的**快照读**是不可见的，因为它是在事务B之后创建的。
4.**事务B执行当前读**：`SELECT * FROM users WHERE age > 20 FOR UPDATE;` // 准备修改这些记录。
    *   这个 `FOR UPDATE` 是**当前读**，它必须看到最新的、已提交的数据，以确保它锁住的是正确的、最新的数据集。
    *   于是，它看到了事务A刚刚插入的那条新记录（`age=25`）。
5.**矛盾出现**：
    *   同一个事务B中，第一次的**快照读**返回10条记录。
    *   第二次的**当前读**返回11条记录。
    *   这个“多出来”的记录，就是幻影行。**幻读发生了**。

3. 为什么InnoDB的“可重复读”不能完全防止这种幻读？   
InnoDB的MVCC通过**一致性读视图**完美解决了**快照读**的幻读问题。在同一个事务里，无论你进行多少次快照读，结果都是一致的。
但是，当你混入**当前读**时，情况就变了。当前读**不受**该事务快照的约束，它必须去读取最新的数据并加锁，否则：
*   `UPDATE` 会更新到错误的数据。
*   `DELETE` 会删除错误的数据。
*   `SELECT ... FOR UPDATE` 会锁住错误的数据集，导致后续的更新基于过时信息。
解决方案：Next-Key Locks
为了在 **可重复读** 级别下解决幻读，InnoDB引入了 **临键锁**。
*   当执行 `SELECT ... FOR UPDATE` 时，它不仅会锁住满足条件的**已有记录**（行锁），还会锁住这些记录之间的**间隙**（Gap Lock）。
*   在上面的例子中，当事务B执行 `SELECT ... FOR UPDATE` 时，它除了锁住那10条已有的记录，还会锁住 `age > 20` 这个范围内的所有“间隙”。这样，事务A试图插入一条 `age=25` 的新记录时，会因为要插入的“位置”被间隙锁锁住而**阻塞等待**，直到事务B提交。
*   这就保证了在事务B中，快照读和当前读看到的数据范围是一致的，从而彻底避免了幻读。

总结  
1.  **标准定义**：幻读是同一事务内两次查询**结果集**数量不同。
2.  **技术根源（以InnoDB为例）**：幻读是由于在**可重复读**隔离级别下，同一个事务中混合使用了**快照读**（读取历史快照）和**当前读**（读取最新数据并加锁）导致的可见性差异。
3.  **解决机制**：InnoDB通过 **Next-Key Locking（行锁+间隙锁）** 来阻止其他事务的插入操作，从而保证了即使在有当前读的情况下，也能避免幻读。

### @Transactional(readOnly = true) 
一个专门用于优化只读操作的事务注解配置。应该在任何确定只包含数据查询操作的Service方法上使用它。   
它通过向底层的数据库和持久化框架（如JPA/Hibernate）提供一个明确的“提示”（Hint），告知它们本次事务中不包含任何写入操作

  
主要从以下三个层面进行优化：
1. 数据库层面 (JDBC Driver)  
**读写分离路由：**  
在配置了读写分离数据源的架构中，readOnly = true 是最重要的路由依据。  
当Spring框架检测到这个标志时，它会指示数据源路由器将SQL查询发送到只读副本（Read Replica）数据库。  
这极大地减轻了主数据库（Master）的压力，使其能专注于处理写请求，从而提升整个系统的吞吐量。   
**禁止不必要的日志记录：**  
数据库知道这个事务是只读的，因此可以跳过为该事务生成回滚日志（Undo/Redo Log）。这减少了磁盘I/O和CPU的开销。   
**驱动级别的优化：**  
某些JDBC驱动在接收到只读提示后，可能会执行一些内部优化，例如设置更合适的抓取大小（Fetch Size）或调整网络包的协议。
2. 持久化框架层面 (JPA/Hibernate)  
这是最显著的优化点之一，尤其是在使用Hibernate时。   
**关闭脏检查（Dirty Checking）：**
在标准的读写事务中，Hibernate会将从数据库加载的实体（Entity）放入一级缓存（Session Cache）中，并保留一个原始状态的快照。   
当事务提交时，Hibernate必须遍历缓存中的所有实体，将它们的当前状态与快照进行比较，以找出被修改过的“脏”数据，然后生成UPDATE语句同步到数据库。这个过程称为脏检查。   
当设置了 readOnly = true 时，Hibernate会完全跳过脏检查这个步骤。对于加载了大量实体的事务，这可以节省大量的CPU时间和内存，避免了成百上千次的对象比较。  
**设置Flush模式：**  
Hibernate会将 FlushMode 设置为 MANUAL 或 NEVER。  
这意味着即使你在代码中意外地修改了实体对象的状态，Hibernate也不会在事务提交时将这些变更刷新（flush）到数据库。这不仅提升了性能，也从侧面保证了只读事务的“只读”特性。
3. Spring框架层面  
Spring本身不直接执行优化，但它扮演着至关重要的“指挥官”角色。  
它负责解析 @Transactional 注解，并将 readOnly 这个标志正确地传递给底层的事务管理器（Transaction Manager）、数据源（DataSource）和JPA提供者（JPA Provider）。

注意事项与常见误区   
它是一个“君子协定”：一个提示，而不是一个强制约束。如果你在标记为只读的事务中尝试执行写操作，其结果取决于你的持久化提供者和数据库驱动。大多数情况下（如使用Hibernate），会在事务提交时抛出异常，但并非所有情况都如此。因此，开发者有责任遵守这个约定。   
方法调用链：如果一个读写方法（readOnly=false）调用了一个只读方法（readOnly=true），并且传播级别为 REQUIRED，那么只读方法会加入到已存在的读写事务中，readOnly=true 的设置会被忽略。事务的读写属性由最外层的事务发起者决定。   
不仅仅是SELECT：只要是不改变数据的操作，都可以认为是只读的。例如，调用数据库的只读存储过程。


### 并发情况下的库存扣减问题--乐观锁
为什么 `productMapper.deductStockWithVersion` 方法能实现乐观锁机制。
乐观锁的核心在于"乐观"地认为并发冲突不常发生，所以不会在操作数据前加锁，而是在更新时检查数据是否被其他线程修改过。

**乐观锁的关键要素**  
deductStockWithVersion方法的 SQL 实现：
```sql
UPDATE product_info 
SET stock = stock - #{quantity}, version = version + 1 
WHERE id = #{id} 
  AND stock >= #{quantity} 
  AND version = #{version} 
  AND deleted = 0
```
这个 SQL 语句包含了乐观锁的核心机制：
1. **版本号检查**：`version = #{version}` 确保只有当数据库中记录的版本号与我们查询时的版本号一致时，才会执行更新操作
2. **版本号更新**：`version = version + 1` 在更新数据的同时将版本号加1
3. **库存检查**：`stock >= #{quantity}` 确保库存充足

**工作流程**
1. **读取商品信息**：
   ```java
   ProductDO product = productMapper.findByIdAndStatus(item.getProductId(), 1);
   // 此时获取到 product.getVersion() = 1
   ```
2. **尝试扣减库存**：
   ```java
   int updateCount = productMapper.deductStockWithVersion(item.getProductId(), item.getQuantity(), product.getVersion());
   // 传入版本号 1
   ```
3. **SQL 执行情况**：
    - 如果没有其他线程修改过该商品，数据库中版本号仍为 1，更新成功，返回 updateCount = 1
    - 如果有其他线程已经修改过该商品，数据库中版本号已变为 2，而我们传入的还是 1，条件不满足，更新失败，返回 updateCount = 0  

**举例说明**  
假设有两个用户同时购买同一商品：
1. 用户A和用户B同时读取商品信息，得到版本号都是 1，库存为 10
2. 用户A先执行扣减库存 3 件，SQL 执行成功，库存变为 7，版本号变为 2
3. 用户B随后执行扣减库存 5 件，但由于数据库中版本号已经是 2，而用户B传入的版本号是 1，SQL 条件不满足，更新失败
4. 用户B的 `updateCount` 返回 0，程序检测到并发冲突，提示用户重新下单

这就是为什么 `deductStockWithVersion` 方法能实现乐观锁的原因，它通过版本号机制来检测并发冲突，而不是通过数据库锁机制。

### 乐观锁+RocketMQ实现一致性：
订单创建时只做基本验证，不扣减库存，发送消息到RocketMQ
消费者中使用乐观锁机制扣减库存
如果扣减失败，通过异常机制触发消息重试
保留了库存回滚机制确保数据一致性

### 定时任务补偿机制

### 读写分离一致性保障机制：
创建了动态数据源路由类，支持根据注解切换主从数据库
实现了数据源上下文持有者，用于在线程本地存储当前数据源类型
创建了数据源注解和切面，用于自动切换数据源
在OrderServiceImpl的关键方法上添加了数据源注解：
写操作（创建、更新、删除）使用主库（MASTER）
读操作（查询）使用从库（SLAVE）

好的，我们来全面总结一下在分布式系统中常见的几种数据一致性保障策略。
数据一致性是指在分布式系统中，多个数据副本在同一时刻是否具有相同的值。根据业务对一致性要求的强弱，可以分为强一致性、弱一致性、最终一致性等不同级别。
以下是对您提到的几种策略以及其他关键策略的详细总结：
1. 强一致性策略   
a. 两阶段提交 (2PC - Two-Phase Commit)  
核心思想: 引入一个“协调者”来统一管理所有“参与者”的事务提交。   
阶段一 (Prepare): 协调者询问所有参与者是否可以执行事务，参与者执行事务但不提交，并锁定资源。   
阶段二 (Commit/Abort): 如果所有参与者都回复“可以”，协调者就通知所有参与者commit；否则，通知所有参与者回滚。   
优点: 原理简单，实现了数据的强一致性。   
缺点: 同步阻塞，性能差；协调者存在单点故障；在第二阶段，如果协调者宕机，参与者会一直锁定资源。  
b. 三阶段提交 (3PC - Three-Phase Commit)  
核心思想: 在2PC的基础上增加了一个“CanCommit”阶段，并引入超时机制，以解决2PC的阻塞问题。   
优点: 相比2PC，降低了阻塞的风险。   
缺点: 依然无法完全避免数据不一致，且协议更复杂，性能更低。   
c. Paxos / Raft 算法   
核心思想: 一种基于“共识”的算法，通过“投票”机制让分布式系统中的多个节点对某个值达成一致。Raft是Paxos的一个更易于理解和实现的工程变体。   
优点: 保证了强一致性，且相比2PC/3PC有更好的可用性和容错性。   
缺点: 算法复杂，实现难度高，性能开销较大。   
适用场景: 分布式锁（如Zookeeper、Etcd）、分布式数据库（如TiDB）的底层实现。
2. 最终一致性策略   
a. RocketMQ/Kafka 事务消息   
核心思想: 利用消息队列的“事务消息”或“半消息”机制，确保本地事务的执行与消息的发送这两个操作成为一个原子单元。   
实现方式 (以RocketMQ为例):  
发送半消息(Prepare Message): 生产者先向MQ Server发送一条“半消息”，该消息对消费者不可见。   
执行本地事务: 生产者执行本地数据库操作。   
提交/回滚消息:  
如果本地事务成功，生产者向MQ Server发送COMMIT，MQ将消息标记为可投递，消费者可以消费。   
如果本地事务失败，生产者向MQ Server发送ROLLBACK，MQ将删除该半消息。   
状态回查: 如果生产者在第二步后宕机，MQ Server会定期向生产者集群回查该消息对应的本地事务状态，以决定是COMMIT还是ROLLBACK。   
优点: 将分布式事务解耦，实现了业务的最终一致性，系统吞吐量高。   
缺点: 依赖消息中间件的可靠性；对业务的侵入性较低但仍需改造。   
适用场景: 跨服务的异步业务通知，如用户注册后发送欢迎邮件、创建订单后通知库存系统等。   
b. TCC (Try-Confirm-Cancel) 模式   
核心思想: 一种补偿型事务模式，将一个大的业务操作分解为Try、Confirm、Cancel三个独立的阶段。   
Try: 尝试执行业务，检查并预留业务资源（如冻结库存、冻结金额）。   
Confirm: 如果所有服务的Try阶段都成功，则逐个调用Confirm接口，真正执行业务操作。   
Cancel: 如果任何一个服务的Try阶段失败，则逐个调用Cancel接口，释放已预留的资源。   
优点: 性能较高（无长期资源锁定），业务层面的原子性，不依赖底层数据库的事务支持。   
缺点: 对业务代码侵入性强，需要为每个操作实现Try-Confirm-Cancel三个接口，开发成本高。   
适用场景: 对一致性要求较高，且流程较长的分布式业务，如复杂的金融、电商下单流程。   
c. Saga 模式  
核心思想: 将一个长事务拆分为多个本地事务，每个本地事务都有一个对应的补偿操作。当Saga中的某个本地事务失败时，会依次调用前面已成功事务的补偿操作来回滚。  
优点: 无长期资源锁定，适合长流程业务，各服务耦合度低。  
缺点: 不保证隔离性（可能看到中间状态的数据），补偿逻辑设计复杂。  
适用场景: 业务流程长、需要保证最终一致性的场景，如机票+酒店+租车预订服务。
3. 兜底与辅助策略  
这些策略通常不单独作为核心方案，而是与其他策略结合使用，作为保障数据一致性的“安全网”。 
a. 定时任务补偿机制  
核心思想: 通过定时任务（如XXL-Job, Quartz）定期扫描数据库中的中间状态或不一致的数据，并执行修复或重试逻辑。  
实现方式: 
在数据表中增加一个状态字段（如status: 0-处理中, 1-成功, 2-失败）和更新时间字段。  
定时任务扫描那些长时间处于“处理中”状态的记录。  
查询关联系统的状态，根据查询结果修复当前记录的状态。  
优点: 实现简单，健壮可靠，是最终一致性方案的完美兜底。  
缺点: 非实时，数据不一致会存在一个时间窗口，可能对数据库造成周期性压力。  
适用场景: 作为所有异步或分布式事务方案的最后一道防线。  
b. 数据校验机制  
核心思想: 在关键操作前后，或定期对数据进行比对和校验，主动发现不一致。  
事前校验: 如使用乐观锁。通过在数据表中增加version字段，更新时检查version是否匹配，防止并发修改导致的数据覆盖。  
事后校验: 定期或在业务流程结束后，比对源系统和目标系统的数据，生成对账单，发现差异后进行人工或自动修复。  
优点: 能主动发现问题，特别是乐观锁能有效防止并发冲突。  
缺点: 对账通常有延迟，且需要额外的开发和计算资源。 
适用场景: 财务系统、订单与库存对账等。
4. 架构层面的保障策略  
这些策略是在系统架构设计层面考虑如何处理一致性问题。  
a. 读写分离一致性保障  
问题: 主从数据库之间存在复制延迟，导致刚在主库写入的数据，立即去从库读可能读不到。  
保障策略: 
强制读主库: 对于一致性要求高的读请求（如用户刚修改完个人信息后立即查看），直接路由到主库读取。  
延迟双删/缓存更新: 在写入主库后，先淘汰缓存，等待一个主从延迟的时间（如1秒），再次淘汰缓存，确保缓存中的脏数据被清除。  
半同步复制: 配置MySQL等数据库的主从复制为半同步模式，确保事务日志至少被一个从库接收后，主库才向客户端返回成功。  
适用场景: 采用了读写分离架构，但部分业务无法容忍主从延迟的场景。  
b. 缓存一致性保障  
问题: 缓存（如Redis）和数据库（如MySQL）这两个数据源之间的数据不一致。  
保障策略: 
Cache Aside Pattern (旁路缓存): 最常用模式。读操作先读缓存，缓存未命中则读数据库，再将数据写入缓存。写操作先更新数据库，然后删除缓存。  
Read/Write Through (读/写穿透): 由缓存服务自身负责与数据库的同步，应用层只与缓存交互。  
Write Back (回写): 写操作只更新缓存，缓存定期批量将数据刷回数据库。  
订阅Binlog: 通过Canal等工具订阅数据库的binlog，当数据发生变更时，由订阅程序自动更新或删除对应的缓存。这是目前较为推荐的自动化方案。  
适用场景: 所有使用缓存来提升系统性能的场景。  
总结对比

|    策略名称     |  一致性级别 | 核心思想 | 复杂度| 典型场景 | 
|:-----------:|:------:|---|---|---|
|   2PC/3PC   |  强一致性  | 协调者统一调度，同步阻塞 | 高 | 单体应用跨库事务 (已较少用) | 
| Paxos/Raft  |  强一致性  | 多数派投票达成共识 | 极高 | 分布式组件底层 (Zookeeper, Etcd) |
|    事务消息     | 最终一致性  | 本地事务与消息发送原子绑定 | 中 | 跨服务异步通知、解耦 |
|     TCC     | 最终一致性  | Try-Confirm-Cancel 补偿 | 高 | 核心交易链路、支付流程 |
|    Saga     | 最终一致性  | 长事务拆分 + 补偿 | 高 | 业务流程长、需要回滚的场景 |
|   定时任务补偿    | 最终一致性  | 定期扫描和修复兜底 | 低 | 所有异步方案的最终保障 |
|    数据校验     |  辅助保障  | 事前预防(乐观锁)或事后对账 | 中 | 并发更新、财务对账 |
|   读写分离策略    |  架构保障  | 解决主从延迟问题 | 中 | 读多写少的系统架构 |
|   缓存一致性策略   |  架构保障  | 保证缓存与DB数据同步 | 中 | 高性能、高并发系统 |

选择哪种策略，需要深入理解业务需求，评估其对一致性、性能、可用性的要求，并综合考虑开发成本和维护复杂度。在复杂的分布式系统中，通常是多种策略的组合使用。

## 优惠券管理
提供优惠券的发放、使用规则配置、有效期管理等功能，增强营销活动灵活性。
## 限购与预售管理
对特定商品设置购买数量上限，同时支持早鸟票预售时间及价格策略设定。
## 促销活动管理
支持限时优惠活动的定时开启与关闭，配合Spring Task实现自动化任务调度。
## 缓存管理
利用Redis缓存热点数据提升系统性能，结合Spring Cache实现本地多级缓存机制。
## 消息通知管理
基于RocketMQ异步处理订单状态变更通知、日志记录等后台任务，提高响应效率。
## 实时通信管理
通过WebSocket实现实时订单状态推送以及客服在线聊天功能，增强用户体验。
## 文件存储管理
集成阿里云OSS实现图片及文档类资源的安全上传与管理，保障多媒体内容存储稳定。
## 数据导入导出管理
基于POI组件提供Excel格式的数据批量导入与导出能力，方便运营人员操作。
## 外部接口调用管理
使用HttpClient发起对外部系统的HTTP请求，用于对接第三方服务如支付网关或物流平台。
## 数据库访问管理
采用MyBatis框架进行MySQL数据库的CRUD操作，并结合PageHelper实现数据分页查询功能。
